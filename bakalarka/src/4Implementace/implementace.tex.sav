% -*-coding: utf-8 -*-

Před tím, než se podíváme na implementaci konkrétních filtrů, probereme některé optimalizace, které budeme často používat. Mnoho z nich je velmi obecných a používají se pro jakýkoliv kód spuštěný na GPU. Naopak některé optimalizace popisované v \cite{CUDA programming g.}, \cite{CUDA best practices} v našem kódu nepoužijeme, neboť pro nás nejsou vhodné. Pro jejich podrobnější popis odkažme čtenáře na zmíněnou literaturu.

\section{Použité optimalizace}
    
    Dvě hlavní třídy optimalizací se týkají optimalizace práce s pamětí a toku instrukcí. V našem případě (a částečně obecně) má vyšší prioritu optimalizace paměti. Přístup do paměti totiž vykazuje narozdíl od vykonávání instrukcí vysokou latenci a náš kód do ní potřebuje přistupovat, v poměru k počtu aritmetických operací, velmi často\footnote{kód je tzv. memory-bound}.
    
    \subsection{Optimalizace paměti}
    
        Následující přehled ukazuje různé běžné paměťové operace seřazené od nejpomalejších:
    \begin{itemize}
      \item Přesun dat z CPU na GPU a zpět
      \item Čtení a zápis do globální paměti GPU
      \item Čtení z texturové cache a dalších cache
      \item Čtení a zápis do sdílené paměti
      \item Čtení a zápis do registrů
    \end{itemize}
    
        \subsubsection{Tok dat mezi CPU a GPU}
        
        Pro jeho slouží celá řada typů RAM optimalizovaných pro konkrétní typy operací (CPU pouze zapíše, GPU pouze čte apod.), stále se však jedná o komunikaci přes PCI Express a ta bude proti komunikaci uvnitř karty vždy řádově pomalejší. Nejefektivnější, a pro náš případ nejproveditelnější optimalizací, je redukce těchto přenosů na nezbytné minimum, což není velký problém -- zpracovávaný obraz (obrazy) stačí na začátku přesunout na GPU, všechny mezivýsledky, které nepotřebujeme, ukládat tamtéž a pouze výsledek poslat zpět.
        
        \subsubsection{Čtení z globální paměti}\label{globální pam opt}
        
        V našem případě sice čteme souvislé bloky paměti, avšak díky závislosti na uživatelské volbě masky a rozměrech obrázku je nemožné zajistit, aby byl čtený blok \emph{zarovnán} na 128 bitů, jak to vyžaduje VS 1.x, pro niž byl kód optimalizován. Filtry však pracují s pamětí velmi extenzivně a dochází k \emph{opakovanému čtení} ze stejného umístění (jeden voxel se promítne do výsledku mnoha okolních), na což je globální paměť zcela nevhodná. Díky malému rozsahu dat zpracovávaných jedním blokem tedy používáme ke čtení výhradně texturovou cache (1D, namapovanou na celý obraz), případně kombinovanou s kopírováním celého bloku dat do sdílené paměti.
        
        Zápis je bezproblémový, protože se jedná vždy jen o jednu hodnotu za thread (nebo skupinu threadů) a tudíž jsou přístupy threadů s po sobě jdoucími \Vr"\cy{threadIdx}" automaticky sdružené.

        \subsubsection{Konstantní paměť}

        Konstantní paměť používáme k uložení všech dlouhodobě neměnných dat -- všech předpočítaných geometrických veličin a část dat masek. U masek neukládáme {\tt wList}, jelikož jeho velikost je proměnná na velké škále a definováním vysoké horní hranice bychom rychle konstatní paměť vyčerpali. {\tt wList} je ovšem na začátku každého kernelu manuálně zkopírován do sdílené paměti pomocí makra {\tt SE\_TO\_SHARED}.
        
        \subsubsection{Optimalizace registrů}
        
        Vzhledem k tomu, že algoritmy pro většinu filtrů jsou poměrně jednoduché, výsledné kernely jsou poměrně malé a na jeden SM se nám vejde velký počet bloků (nebo alespoň threadů), což je ideální, protože se dobře překryjí paměťové latence. Bloky ale bohužel nejsou paměťově tak malé, aby se uplatnilo hardwarové omezení a zvyšování jejich počtu na jednom SM tak bude střídavě narážet na fyzické omezení množsví sdílené paměti (probráno u konkrétních filtrů) a hlavně registrů\footnote{pro představu naše thready spotřebují zhruba 11-23 registrů. To pro VS 1.x (8192 registrů) odpovídá 744-356 threadů/SM, což ještě nenaráží na fyzickou hranici}.
        
        Pro snížení počtu použitých registrů můžeme udělat několik věcí:
        \begin{itemize}
          \item Recyklace proměnných -- proměnné, jejichž obsah není aktuálně potřeba použít pro dočasně např. jako inkrementální proměnné v cyklech.
          \item Řízená výměna rychlosti za menší počet využitých registrů změnou algoritmu (v optimalizaci kompilátoru by ale měla být pořád zapnutá optimalizace na rychlost).
          \item Uložení méně potřebných dat do sdílené paměti, případně konstantních maker do konstantní paměti -- zde je nutné experimentovat, \emph{celková} rychlost může i při větší hustotě bloků/SM klesnout
        \end{itemize}
        
        
        co se vejde do cache, nacacheovat!!, několikanásobné čtení stejných hodnot
        
        co nejvíce šetřit registry .. threadidx v nich zůstávají :(
    
    \subsection{Optimalizace běhu kernelu}
return a goto

překrývání latencí i v L1

odbourávání if-ů -- jak kdy, otestovat, operátor ?,
slabé/silné větve (třeba po větších skupinách se if vyplatí,
viz přiřazování maxima, minima) 

\section{Implementace filtrů na GPU}